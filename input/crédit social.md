---
title: Crédit social chinois
subtitle: 
author: Damien Belvèze
date: 18-10-2021
link_citations: true
bibliography: biblio/Obsidian.bib
biblio_style: csl\ieee.csl
aliases:
  - social credit
tags:
  - capitalisme
  - sciences_politiques
---
# Crédit Social Chinois 

Barême mis en oeuvre par le gouvernement chinois pour récompenser ou stigmatiser les citoyens en fonction de leur conduite et de leurs rapports avec les autres citoyens. Ce crédit est inspiré de la notation que la banque met en place pour juger ses clients en fonction du sérieux de leur gestion personnelle mais étendu à tous les domaines de la vie (y inclues les opinions politiques) et cela au moyen d'un dispositif de surveillance (multiplication des [[Caméras de surveillance|caméras de surveillance]]  à [[reconnaissance faciale]])

![crédit social chinois](credit_social.jpg)

# Le Crédit social dans le sillage des intelligences artificielles

Comme l'indique l'ouvrage "Red Mirror", la Chine en tant qu'Etat autoritaire ne fait que donner le là aux autres nations de l'Ouest disposant à la base d'un régime démocratique. Cette lutte nationaliste pour l'équipement d'outils technologiques avancés ([[Offset strategy]]) au départ pour contrer d'autres puissances, a pour effet de se retourner vers les populations qui sont de plus en plus sujets à des contrôles drastiques en Europe et aux Etats-Unis. Au sein de ces populations, les personnes les plus fragiles (personnes racisées, migrants, minorités sexuelles) sont particulièrement ciblées par ces dispositifs de surveillance. Ces derniers renforcent les inégalités à l'oeuvre en prétendant offrir plus de sécurité à tout un chacun. Ces dérives ne concernent pas seulement les autorités responsables de l'ordre public ou de l'immigration mais tendent aussi à conditionner l'octroi d'aides sociales ou l'accès à certains emplois (recrutements monitorés par IA fonctionnant sur l'[[nformatique affective]])

De plus en plus, les institutions sociales (après les pouvoirs régaliens) ont recours à des outils de surveillance et d'analyse de données liées à des [[grands modèles de langage|intelligences artificielles]] pour poursuivre les fraudeurs ou réduire les allocations sociales aux personnes qui sont supposées ne pas les mériter en vertu des signaux émis par ces outils techniques. 

L'inclusion d'IA dans le fonctionnement de l'aide sociale, et notamment la poursuite de la fraude assistée par l'IA a donné lieu à des échecs retentissants aux Etats-Unis. Notamment Kate Crawford raconte comment 40 000 résidents du Michigan qui n'étaient pas fraudeuses ont du s'acquitter d'une somme importante à la répression des fraudes pour des infractions qu'elles n'avaient pas commises (système MiDAS au Michigan mentionné dans [[@crawfordContreatlasIntelligenceArtificielle2023]], p251)



# bibliographie

