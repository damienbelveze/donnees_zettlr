---
title: explicabilité
subtitle: 
id: 20240107_explicabilité
author: Damien Belvèze
date: 2024-01-07
link_citations: true
bibliography: biblio/Obsidian.bib
biblio_style: csl\ieee.csl
aliases:
  - explicable
  - explicability
tags:
  - informatique
  - culture_numérique
  - IA
---

> « il se pourrait que nous ne soyons plus jamais capables de comprendre les choses que nous  sommes cependant capables de faire »  

Hannah Arendt, citée par Jean-Pierre Dupuy dans La marque du sacré

Capacité à rendre compte du traitement d'un [[algorithme]] dans un cas donné. 

# explicabilité et déresponsabilisation

L'inexplicabilité du traitement des informations par les [[grands modèles de langage|grand modèle de langage]] favorise ce que [[Bernard Stiegler]] appelait la [[prolétarisation]] des savoirs : nous nous remettons à des systèmes de plus en plus sophistiqués et nous sommes de moins en moins capables de comprendre la manière dont ces systèmes fonctionnent, par conséquent, nous sommes de moins en moins capables de corriger et a fortiori d'anticiper leurs dysfonctionnements, ce qui limite finalement notre capacité à agir, alors que le but était de l'accroître.

On observe que les institutions qui utilisent des [[intelligences artificielles]] sont de moins en moins enclines à assumer la responsabilité des dérives ou des dérapages constatés, notamment dans le traitement des affaires policières. Le mot d'ordre semble devenir : "nous ne pouvons être responsables du traitement de systèmes que nous ne comprenons pas" (cf. [[@crawfordContreatlasIntelligenceArtificielle2023]], p230) 

$\newline$
# bibliographie
$\newline$






